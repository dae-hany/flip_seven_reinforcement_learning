"""
Flip Seven 강화학습 훈련을 위한 설정 파일

이 파일은 DQN 에이전트 훈련에 필요한 모든 하이퍼파라미터를 정의합니다.
"""

import os
from datetime import datetime

# ============================================================================
# 환경 설정
# ============================================================================
# 타임스탬프 기반 고유 실행 이름 생성
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
RUN_NAME = f"run_{timestamp}"  # 실행 이름 (예: run_20251118_143022)
OUTPUT_DIR = f"./runs/{RUN_NAME}"  # 모델 체크포인트 및 로그 저장 디렉토리

# 출력 디렉토리 생성
os.makedirs(OUTPUT_DIR, exist_ok=True)# ============================================================================
# 훈련 하이퍼파라미터
# ============================================================================
NUM_TOTAL_GAMES_TO_TRAIN = 1000  # 학습할 전체 게임 수
TARGET_UPDATE_FREQUENCY = 10  # 타겟 네트워크를 N 게임마다 업데이트
REPLAY_BUFFER_SIZE = 50000  # 리플레이 버퍼 크기
BATCH_SIZE = 64  # 배치 크기
GAMMA = 0.99  # 할인률 (discount factor)
LEARNING_RATE = 1e-4  # 학습률 (learning rate)
EPSILON_START = 1.0  # 초기 epsilon (탐험 확률)
EPSILON_END = 0.01  # 최소 epsilon (탐험 확률 하한)
EPSILON_DECAY = 0.995  # 게임마다 epsilon 감소율
MIN_REPLAY_SIZE = 1000  # 이만큼의 transition이 쌓인 후 학습 시작

# ============================================================================
# 네트워크 아키텍처 하이퍼파라미터
# ============================================================================
HAND_NUMBERS_DIM = 13  # 손패 숫자 카드 차원 (0~12)
HAND_MODIFIERS_DIM = 6  # 손패 수정자 카드 차원 (+2, +4, +6, +8, +10, x2)
DECK_COMPOSITION_DIM = 19  # 덱 구성 정보 차원 (카드 카운팅용)
SCORE_DIM = 1  # 총점 차원
HIDDEN_DIM = 128  # 공유 MLP 은닉층 차원

# ============================================================================
# 로깅 및 저장 설정
# ============================================================================
LOG_INTERVAL = 10  # N 게임마다 로그 출력
SAVE_INTERVAL = 100  # N 게임마다 모델 저장
EVAL_GAMES = 10  # 평가 시 플레이할 게임 수
